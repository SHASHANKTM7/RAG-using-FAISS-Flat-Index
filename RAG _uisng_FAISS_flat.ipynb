{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Nessesery Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv  \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.langchain.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    \"\"\"Fetches all valid links from the given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url) \n",
    "        response.raise_for_status()  # Raise error for bad responses (404, 500, etc.)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return set()  # Return an empty set on failure\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = {a.get('href') for a in soup.find_all('a', href=True)}\n",
    "    # Only keep valid links (absolute URLs starting with http)\n",
    "    valid_links = {link for link in links if link.startswith('http')}\n",
    "    \n",
    "    return valid_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links_depth_2(start_url):\n",
    "    \"\"\"Extracts links up to depth 2.\"\"\"\n",
    "    all_links = set()  # Stores all links found\n",
    "    \n",
    "    # Depth 1: Get links from the start URL\n",
    "    level_1_links = get_links(start_url)\n",
    "    all_links.update(level_1_links)  # Store these links\n",
    "\n",
    "    # Depth 2: Get links from each link found at depth 1\n",
    "    for link in level_1_links:\n",
    "        level_2_links = get_links(link)  # Extract links from each level 1 link\n",
    "        all_links.update(level_2_links)  # Store these links\n",
    "\n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = \"https://python.langchain.com/docs/\"  # Replace with any valid website\n",
    "links = extract_links_depth_2(start_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/baskaryan', 'https://academy.langchain.com/', 'https://github.com/langchain-ai/langgraph/edit/main/docs/docs/concepts/index.md', 'https://github.com/langchain-ai/langgraph/blob/main/CONTRIBUTING.md', 'https://langchain-ai.github.io/langgraph/concepts/high_level/', 'https://python.langchain.com/docs/concepts/messages/', 'https://js.langchain.com/docs/', 'https://python.langchain.com/docs/introduction', 'https://research.google/pubs/pub37252/', 'https://github.com/langchain-ai/langchain/releases', 'https://www.smith.langchain.com', 'https://github.com/langchain-ai/langchainjs/blob/main/CONTRIBUTING.md', 'https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.Command', 'https://github.com/langchain-ai/langgraph/edit/main/docs/docs/tutorials/index.md', 'https://docs.smith.langchain.com/reference/js', 'https://github.com/features/actions', 'https://www.youtube.com/about/copyright/', 'https://github.com/features/discussions', 'https://python.langchain.com/docs/tutorials/rag/', 'https://camo.githubusercontent.com/8334388441584b2923a07d46c2e3d5e55af9e2b4ed9f73e8150689a5074d7b1c/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f6c616e67636861696e', 'https://smith.langchain.com/hub', 'https://github.com/langchain-ai/langchainjs/blob/main/SECURITY.md', 'https://docs.smith.langchain.com/', 'https://js.langchain.com/docs/tutorials/rag/', 'https://github.com/rlancemartin', 'https://arxiv.org/abs/2403.14403', 'https://github.com/hinthornw', 'https://blog.langchain.dev/tag/case-studies/', 'https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages', 'https://raw.githubusercontent.com/langchain-ai/.github/main/profile/logo-light.svg#gh-dark-mode-only', 'https://interrupt.langchain.com/', 'https://github.com/langchain-ai/langchainjs/blob/main/langchain', 'https://twitter.com/LangChainAI', 'https://github.com/features/codespaces', 'https://support.github.com', 'https://docs.github.com', 'https://github.com/langchain-ai/langgraph/edit/main/docs/docs/how-tos/index.md', 'https://langchain.com', 'https://python.langchain.com', 'https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver', 'https://github.com/customer-stories', 'https://resources.github.com/learn/pathways', 'https://www.youtube.com/about/', 'https://github.com/dev2049', 'https://github.com/langchain-ai/weblangchain', 'https://github.com/eyurtsev', 'https://blog.langchain.dev/tag/in-the-loop/', 'https://js.langchain.com/docs/get_started/introduction/', 'https://smith.langchain.com', 'https://squidfunk.github.io/mkdocs-material/', 'https://trust.langchain.com/', 'https://airtable.com/appGjCAN6126Jm7K8/pagNAp7niHQzRH8zk/form', 'https://langchain-ai.github.io/langgraph/concepts/streaming', 'https://python.langchain.com/v0.1/docs/get_started/introduction', 'https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers', 'https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode', 'https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax', 'https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/langchain-ai/langchain', 'https://docs.smith.langchain.com/evaluation/how_to_guides/compare_experiment_results', 'https://github.com/features/issues', 'https://github.com/langchain-ai/langchain/issues', 'https://www.youtube.com/@LangChain', 'https://changelog.langchain.com/', 'https://www.langchain.com', 'https://python.langchain.com/docs/how_to/custom_tools/', 'https://python.langchain.com/docs/tutorials/#orchestration', 'https://blog.langchain.dev/', 'https://python.langchain.com/docs/tutorials/chatbot/', 'https://www.youtube.com/about/press/', 'https://js.langchain.com/', 'https://github.com/cbornet', 'https://github.com/', 'https://github.com/langchain-ai', 'https://docs.smith.langchain.com/prompt_engineering/how_to_guides/prompts/manage_prompts_programatically', 'https://status.smith.langchain.com/', 'https://langchain-ai.github.io/langgraph/', 'https://langchain-ai.github.io/langgraph/reference/graphs/', 'https://drive.google.com/drive/folders/17xybjzmVBdsQA-VxouuGLxF6bDsHDe80?usp=sharing', 'https://python.langchain.com/docs/concepts/document_loaders/', 'https://github.com/vowelparrot', 'https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.interrupt', 'https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.tools_condition', 'https://github.com/features/security', 'https://python.langchain.com/', 'https://smith.langchain.com/public/29ba22b5-6d40-4fbe-8d27-b369e3329c84/r', 'https://smith.langchain.com/public/51a62351-2f0a-4058-91cc-9996c5561428/r', 'https://templates.langchain.com', 'https://github.com/langchain-ai/langchain/raw/refs/heads/master/docs/docs/introduction.mdx', 'https://github.com/langchain-ai/langchainjs/blob/main/docs/core_docs/static/svg/langchain_stack_062024.svg', 'https://star-history.com/#langchain-ai/langchain', 'https://www.langchain.com/event-terms', 'https://github.com/langchain-ai/langsmith-docs', 'https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/', 'https://github.com/langchain-ai/langchain', 'https://weblangchain.vercel.app', 'https://python.langchain.com/docs/concepts/tool_calling/', 'https://github.com/enterprise/advanced-security', 'https://github.com/ccurme', 'https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph', 'https://github.blog', 'https://github.com/collections', 'https://python.langchain.com/en/latest/', 'https://langchain-ai.github.io/langgraphjs/', 'https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html', 'https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html', 'https://github.com/langchain-ai/langchainjs/actions/workflows/ci.yml', 'https://github.com/langchain-ai/langchainjs/blob/main/libs/langchain-community', 'https://python.langchain.com/docs/integrations/tools/tavily_search/', 'https://blog.langchain.dev/ally-financial-collaborates-with-langchain-to-deliver-critical-coding-module-to-mask-personal-identifying-information-in-a-compliant-and-safe-manner/', 'https://python.langchain.com/docs/tutorials/', 'https://js.langchain.com/docs/concepts/#langgraphjs', 'https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.END', 'https://github.com/langchain-ai/langgraph/edit/main/docs/docs/tutorials/introduction.ipynb', 'https://github.com/features', 'https://pepy.tech/project/langgraph', 'https://js.langchain.com/docs/concepts/lcel', 'https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/', 'https://www.youtube.com/creators/', 'https://smith.langchain.com/public/7ebb7827-378d-49fe-9f6c-5df0e90086c8/r', 'https://codespaces.new/langchain-ai/langchain', 'https://github.com/langchain-ai/langchain/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CPlease+write+a+comprehensive+title+after+the+%27DOC%3A+%27+prefix%3E', 'https://github.com/langchain-ai/langchain-extract/', 'https://langchain-ai.github.io/langgraph/tutorials/', 'https://beam.apache.org/', 'https://docs.github.com/', 'https://langchain-ai.github.io/langgraph/cloud/', 'https://langchain-ai.github.io/langgraph/tutorials/introduction/', 'https://support.github.com?tags=dotcom-footer', 'https://github.com/langchain-ai/langchain/edit/master/docs/docs/introduction.mdx', 'https://js.langchain.com/docs/integrations/platforms/', 'https://www.githubstatus.com/', 'https://github.com/langchain-ai/opengpts', 'https://api.smith.langchain.com/redoc', 'https://github.com/langchain-ai/agent-protocol', 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio', 'https://www.youtube.com/watch?v=29XE10U6ooc', 'https://blog.langchain.dev/llms-accelerate-adyens-support-team-through-smart-ticket-routing-and-support-agent-copilot/', 'https://langchain-ai.github.io/langgraph/concepts/langgraph_platform', 'https://github.com/langchain-ai/langgraphjs/', 'https://github.com/langchain-ai/langgraph/edit/main/docs/docs/index.md', 'https://langchain-ai.github.io/langgraph/how-tos/', 'https://python.langchain.com/docs/concepts/prompt_templates/', 'https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode', 'https://github.com/hwchase17', 'https://api.python.langchain.com/', 'https://docs.github.com/site-policy/github-terms/github-terms-of-service', 'https://tavily.com/', 'https://js.langchain.com', 'https://python.langchain.com/docs/concepts/chat_models/', 'https://github.com/langchain-ai/langchain/tree/master/templates', 'https://js.langchain.com/docs/introduction/', 'https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.START', 'https://python.langchain.com/api_reference/', 'https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages', 'https://langchain-ai.github.io/langgraph/concepts/sdk', 'https://github.com/dissorial/doc-chatbot', 'https://smith.langchain.com/', 'https://js.langchain.com/docs/tutorials/', 'https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation', 'https://python.langchain.com/docs/concepts/tools/', 'https://github.com/langchain-ai/langchain/blob/master/docs/docs/introduction.mdx', 'https://python.langchain.com/v0.2/docs/introduction', 'https://github.com/langchain-ai/langchain/blob/master/cookbook/README.md', 'https://js.langchain.com/docs/concepts/#agents', 'https://github.com/langchain-ai/langchainjs', 'https://langchain-ai.github.io/langgraph/concepts/', 'https://python.langchain.com/docs/integrations/providers/', 'https://python.langchain.com/v0.2/api_reference/reference.html', 'https://python.langchain.com/docs/concepts/retrievers/', 'https://docs.github.com/site-policy/privacy-policies/github-privacy-statement', 'https://github.com/jacoblee93', 'https://github.com/solutions/executive-insights', 'https://python.langchain.com/docs/tutorials/extraction/', 'https://github.com/langchain-ai/langgraph', 'https://academy.langchain.com/courses/intro-to-langgraph', 'https://smith.langchain.com/public/4fbd7636-25af-4638-9587-5a02fdbb0172/r', 'https://developers.google.com/youtube', 'https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&utm_source=ythp&utm_medium=LeftNav&utm_content=txt&u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen', 'https://arxiv.org/pdf/2401.15884.pdf', 'https://github.com', 'https://chat.langchain.com', 'https://js.langchain.com/docs/introduction', 'https://www.langchain.com/built-with-langgraph', 'https://github.com/features/copilot', 'https://github.com/security', 'https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html', 'https://blog.langchain.dev/langchain-partners-with-elastic-to-launch-the-elastic-ai-assistant/', 'https://python.langchain.com/docs/concepts/', 'https://python.langchain.com/docs/how_to/', 'https://arxiv.org/abs/2310.11511', 'https://smith.langchain.com/public/7527e308-9502-4894-b347-f34385740d5a/r', 'https://langchain-ai.github.io/langgraph/concepts/deployment_options/', 'https://discord.gg/cU2adEyC7w', 'https://arxiv.org/abs/2404.10952v1', 'https://github.com/langchain-ai/social-media-agent', 'https://docs.smith.langchain.com/evaluation/how_to_guides/use_langchain_off_the_shelf_evaluators', 'https://python.langchain.com/docs/introduction/', 'https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html', 'https://github.com/langchain-ai/langserve', 'https://github.com/pricing', 'https://github.com/langchain-ai/langgraphjs', 'https://blog.langchain.dev', 'https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/langchain-ai/langchainjs', 'https://js.langchain.com/docs/how_to/lcel_cheatsheet/', 'https://github.com/tomasonjo', 'https://docs.smith.langchain.com', 'https://github.com/readme', 'https://github.com/langchain-ai/chat-langchain', 'https://github.com/langchain-ai/langsmith-docs/issues/new?title=DOC%3A+%3CPlease+write+a+comprehensive+title+after+the+%27DOC%3A+%27+prefix%3E', 'https://langchain-ai.github.io/langgraph/concepts/langgraph_cli', 'https://js.langchain.com/docs/concepts', 'https://partner.github.com', 'https://github.com/efriis', 'https://github.com/leo-gan', 'https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolCallId.html', 'https://langchain-ai.github.io/langgraph/concepts/double_texting', 'https://github.com/enterprise', 'https://smith.langchain.com/public/9f0f87e3-56a7-4dde-9c76-b71675624e91/r', 'https://github.com/enterprise/startups', 'https://github.com/features/code-search', 'https://github.com/langchain-ai/langgraph/issues', 'https://www.langchain.com/join-community', 'https://python.langchain.com/docs/concepts/text_splitters/', 'https://codespaces.new/langchain-ai/langchainjs', 'https://docs.smith.langchain.com/reference/python', 'https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html', 'https://github.com/topics', 'https://github.com/langchain-ai/langchain/graphs/contributors', 'https://raw.githubusercontent.com/langchain-ai/.github/main/profile/logo-dark.svg#gh-light-mode-only', 'https://github.com/langchain-ai/langchainjs/blob/main/langchain-core', 'https://python.langchain.com/docs/concepts/structured_outputs/', 'https://github.com/langchain-ai/open-canvas', 'https://api.js.langchain.com', 'https://js.langchain.com/docs/tutorials/chatbot', 'https://langchain-ai.github.io/langgraph', 'https://langchain-ai.github.io/langgraph/concepts/persistence/', 'https://www.langchain.com/', 'https://www.linkedin.com/company/langchain/', 'https://github.com/langchain-ai/executive-ai-assistant', 'https://python.langchain.com/docs/get_started/introduction', 'https://python.langchain.com/v0.2/api_reference/', 'https://www.langchain.com/contact-sales', 'https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition', 'https://github.com/trending', 'https://api.python.langchain.com', 'https://github.com/langchain-ai/langchain/actions/workflows/check_diffs.yml', 'https://pypistats.org/packages/langchain-core', 'https://twitter.com/langchainai', 'https://github.com/team', 'https://github.com/langchain-ai/chat-langchainjs', 'https://api.python.langchain.com/en/v0.1/', 'https://github.com/langchain-ai/langsmith-sdk', 'https://skills.github.com', 'https://www.youtube.com/ads/', 'https://python.langchain.com/docs/concepts/runnables/', 'https://networkx.org/documentation/latest/', 'https://docs.smith.langchain.com/observability/how_to_guides/tracing/trace_with_langgraph', 'https://resources.github.com', 'https://github.com/features/code-review', 'https://python.langchain.com/docs/contributing/', 'https://langchain-ai.github.io/langgraph/concepts/langgraph_server', 'https://langchain-ai.github.io/langgraph/concepts/#langgraph-platform', 'https://opensource.org/licenses/MIT', 'https://github.com/nfcampos', 'https://www.youtube.com/about/policies/', 'https://github.com/langchain-ai/langchain-nextjs-template']\n"
     ]
    }
   ],
   "source": [
    "list_link=list(links)\n",
    "print(list_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying To Remove Invalid Links By Validating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_links(url):\n",
    "    \"\"\"Check if a link is valid and reachable.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.status_code == 200  # Valid if status code is 200\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False  # Invalid link\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validlink = [link for link in list_link if valid_links(link)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(validlink))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving It As CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Write list to a CSV file (as a single row)\n",
    "with open(\"recent_links.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(validlink)  # Save as a single row with values separated by commas\n",
    "\n",
    "print(\"CSV file saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validlink=set(validlink)\n",
    "len(validlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\shashank_\\agenticai\\env2\\lib\\site-packages (5.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extractor(url):\n",
    "    try:\n",
    "        response=requests.get(url,timeout=5)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    text=soup.get_text(separator=' ',strip=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHASHANK_\\anaconda3\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    }
   ],
   "source": [
    "info_list=[]\n",
    "for i in validlink:\n",
    "    fultext=text_extractor(i)\n",
    "    info_list.append(fultext)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "validlink=(list(validlink))\n",
    "print(len(validlink))\n",
    "print(len(info_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "      <td>baskaryan (Bagatur) · GitHub Skip to content N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://academy.langchain.com/</td>\n",
       "      <td>LangChain Academy Docs Python LangChain LangSm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/langchain-ai/langgraph/edit...</td>\n",
       "      <td>Sign in to GitHub · GitHub Skip to content You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/langchain-ai/langgraph/blob...</td>\n",
       "      <td>langgraph/CONTRIBUTING.md at main · langchain-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://langchain-ai.github.io/langgraph/conce...</td>\n",
       "      <td>Why LangGraph? Skip to content Join us at Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>https://langchain-ai.github.io/langgraph/conce...</td>\n",
       "      <td>Concepts Skip to content Join us at Interrupt:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>https://opensource.org/licenses/MIT</td>\n",
       "      <td>The MIT License – Open Source Initiative Skip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>https://github.com/nfcampos</td>\n",
       "      <td>nfcampos (Nuno Campos) · GitHub Skip to conten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>https://www.youtube.com/about/policies/</td>\n",
       "      <td>YouTube Community Guidelines and policies - Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "      <td>GitHub - langchain-ai/langchain-nextjs-templat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "0                         https://github.com/baskaryan   \n",
       "1                       https://academy.langchain.com/   \n",
       "2    https://github.com/langchain-ai/langgraph/edit...   \n",
       "3    https://github.com/langchain-ai/langgraph/blob...   \n",
       "4    https://langchain-ai.github.io/langgraph/conce...   \n",
       "..                                                 ...   \n",
       "256  https://langchain-ai.github.io/langgraph/conce...   \n",
       "257                https://opensource.org/licenses/MIT   \n",
       "258                        https://github.com/nfcampos   \n",
       "259            https://www.youtube.com/about/policies/   \n",
       "260  https://github.com/langchain-ai/langchain-next...   \n",
       "\n",
       "                                             documents  \n",
       "0    baskaryan (Bagatur) · GitHub Skip to content N...  \n",
       "1    LangChain Academy Docs Python LangChain LangSm...  \n",
       "2    Sign in to GitHub · GitHub Skip to content You...  \n",
       "3    langgraph/CONTRIBUTING.md at main · langchain-...  \n",
       "4    Why LangGraph? Skip to content Join us at Inte...  \n",
       "..                                                 ...  \n",
       "256  Concepts Skip to content Join us at Interrupt:...  \n",
       "257  The MIT License – Open Source Initiative Skip ...  \n",
       "258  nfcampos (Nuno Campos) · GitHub Skip to conten...  \n",
       "259  YouTube Community Guidelines and policies - Ho...  \n",
       "260  GitHub - langchain-ai/langchain-nextjs-templat...  \n",
       "\n",
       "[261 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame=pd.DataFrame({'URL':validlink,'documents':info_list})\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "      <td>baskaryan (bagatur) · github skip to content n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://academy.langchain.com/</td>\n",
       "      <td>langchain academy docs python langchain langsm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/langchain-ai/langgraph/edit...</td>\n",
       "      <td>sign in to github · github skip to content you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/langchain-ai/langgraph/blob...</td>\n",
       "      <td>langgraph/contributing.md at main · langchain-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://langchain-ai.github.io/langgraph/conce...</td>\n",
       "      <td>why langgraph? skip to content join us at inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>https://langchain-ai.github.io/langgraph/conce...</td>\n",
       "      <td>concepts skip to content join us at interrupt:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>https://opensource.org/licenses/MIT</td>\n",
       "      <td>the mit license – open source initiative skip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>https://github.com/nfcampos</td>\n",
       "      <td>nfcampos (nuno campos) · github skip to conten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>https://www.youtube.com/about/policies/</td>\n",
       "      <td>youtube community guidelines and policies - ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "      <td>github - langchain-ai/langchain-nextjs-templat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "0                         https://github.com/baskaryan   \n",
       "1                       https://academy.langchain.com/   \n",
       "2    https://github.com/langchain-ai/langgraph/edit...   \n",
       "3    https://github.com/langchain-ai/langgraph/blob...   \n",
       "4    https://langchain-ai.github.io/langgraph/conce...   \n",
       "..                                                 ...   \n",
       "256  https://langchain-ai.github.io/langgraph/conce...   \n",
       "257                https://opensource.org/licenses/MIT   \n",
       "258                        https://github.com/nfcampos   \n",
       "259            https://www.youtube.com/about/policies/   \n",
       "260  https://github.com/langchain-ai/langchain-next...   \n",
       "\n",
       "                                             documents  \n",
       "0    baskaryan (bagatur) · github skip to content n...  \n",
       "1    langchain academy docs python langchain langsm...  \n",
       "2    sign in to github · github skip to content you...  \n",
       "3    langgraph/contributing.md at main · langchain-...  \n",
       "4    why langgraph? skip to content join us at inte...  \n",
       "..                                                 ...  \n",
       "256  concepts skip to content join us at interrupt:...  \n",
       "257  the mit license – open source initiative skip ...  \n",
       "258  nfcampos (nuno campos) · github skip to conten...  \n",
       "259  youtube community guidelines and policies - ho...  \n",
       "260  github - langchain-ai/langchain-nextjs-templat...  \n",
       "\n",
       "[261 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['documents']=data_frame['documents'].str.lower()\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SHASHANK_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to download the punkt tokenizer models if not already done\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['tokens']= data_frame['documents'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Puctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(tokens):\n",
    "    cleaned_tokens = []  # Initialize an empty list\n",
    "    for word in tokens:\n",
    "        cleaned_word = re.sub(r'[^\\w\\s]', '', word)  # Remove punctuation\n",
    "        if cleaned_word:  # Only add non-empty words\n",
    "            cleaned_tokens.append(cleaned_word)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['cleaned_tokens']=data_frame['tokens'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform lemmatization\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatized_words = []\n",
    "    for word in tokens:\n",
    "        lemma = lemmatizer.lemmatize(word)  # Convert to lemma\n",
    "        lemmatized_words.append(lemma)\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['lemmatized']=data_frame['cleaned_tokens'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list=data_frame['lemmatized'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_link=data_frame['URL'].to_list()\n",
    "# data_frame=data_frame.drop(0, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying To Do Striding And Padding And Storing Data In Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>documents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "      <td>baskaryan (bagatur) · github skip to content n...</td>\n",
       "      <td>[baskaryan, (, bagatur, ), ·, github, skip, to...</td>\n",
       "      <td>[baskaryan, bagatur, github, skip, to, content...</td>\n",
       "      <td>[baskaryan, bagatur, github, skip, to, content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://academy.langchain.com/</td>\n",
       "      <td>langchain academy docs python langchain langsm...</td>\n",
       "      <td>[langchain, academy, docs, python, langchain, ...</td>\n",
       "      <td>[langchain, academy, docs, python, langchain, ...</td>\n",
       "      <td>[langchain, academy, doc, python, langchain, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/langchain-ai/langgraph/edit...</td>\n",
       "      <td>sign in to github · github skip to content you...</td>\n",
       "      <td>[sign, in, to, github, ·, github, skip, to, co...</td>\n",
       "      <td>[sign, in, to, github, github, skip, to, conte...</td>\n",
       "      <td>[sign, in, to, github, github, skip, to, conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/langchain-ai/langgraph/blob...</td>\n",
       "      <td>langgraph/contributing.md at main · langchain-...</td>\n",
       "      <td>[langgraph/contributing.md, at, main, ·, langc...</td>\n",
       "      <td>[langgraphcontributingmd, at, main, langchaina...</td>\n",
       "      <td>[langgraphcontributingmd, at, main, langchaina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://langchain-ai.github.io/langgraph/conce...</td>\n",
       "      <td>why langgraph? skip to content join us at inte...</td>\n",
       "      <td>[why, langgraph, ?, skip, to, content, join, u...</td>\n",
       "      <td>[why, langgraph, skip, to, content, join, us, ...</td>\n",
       "      <td>[why, langgraph, skip, to, content, join, u, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>https://langchain-ai.github.io/langgraph/conce...</td>\n",
       "      <td>concepts skip to content join us at interrupt:...</td>\n",
       "      <td>[concepts, skip, to, content, join, us, at, in...</td>\n",
       "      <td>[concepts, skip, to, content, join, us, at, in...</td>\n",
       "      <td>[concept, skip, to, content, join, u, at, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>https://opensource.org/licenses/MIT</td>\n",
       "      <td>the mit license – open source initiative skip ...</td>\n",
       "      <td>[the, mit, license, –, open, source, initiativ...</td>\n",
       "      <td>[the, mit, license, open, source, initiative, ...</td>\n",
       "      <td>[the, mit, license, open, source, initiative, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>https://github.com/nfcampos</td>\n",
       "      <td>nfcampos (nuno campos) · github skip to conten...</td>\n",
       "      <td>[nfcampos, (, nuno, campos, ), ·, github, skip...</td>\n",
       "      <td>[nfcampos, nuno, campos, github, skip, to, con...</td>\n",
       "      <td>[nfcampos, nuno, campos, github, skip, to, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>https://www.youtube.com/about/policies/</td>\n",
       "      <td>youtube community guidelines and policies - ho...</td>\n",
       "      <td>[youtube, community, guidelines, and, policies...</td>\n",
       "      <td>[youtube, community, guidelines, and, policies...</td>\n",
       "      <td>[youtube, community, guideline, and, policy, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "      <td>github - langchain-ai/langchain-nextjs-templat...</td>\n",
       "      <td>[github, -, langchain-ai/langchain-nextjs-temp...</td>\n",
       "      <td>[github, langchainailangchainnextjstemplate, l...</td>\n",
       "      <td>[github, langchainailangchainnextjstemplate, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "0                         https://github.com/baskaryan   \n",
       "1                       https://academy.langchain.com/   \n",
       "2    https://github.com/langchain-ai/langgraph/edit...   \n",
       "3    https://github.com/langchain-ai/langgraph/blob...   \n",
       "4    https://langchain-ai.github.io/langgraph/conce...   \n",
       "..                                                 ...   \n",
       "256  https://langchain-ai.github.io/langgraph/conce...   \n",
       "257                https://opensource.org/licenses/MIT   \n",
       "258                        https://github.com/nfcampos   \n",
       "259            https://www.youtube.com/about/policies/   \n",
       "260  https://github.com/langchain-ai/langchain-next...   \n",
       "\n",
       "                                             documents  \\\n",
       "0    baskaryan (bagatur) · github skip to content n...   \n",
       "1    langchain academy docs python langchain langsm...   \n",
       "2    sign in to github · github skip to content you...   \n",
       "3    langgraph/contributing.md at main · langchain-...   \n",
       "4    why langgraph? skip to content join us at inte...   \n",
       "..                                                 ...   \n",
       "256  concepts skip to content join us at interrupt:...   \n",
       "257  the mit license – open source initiative skip ...   \n",
       "258  nfcampos (nuno campos) · github skip to conten...   \n",
       "259  youtube community guidelines and policies - ho...   \n",
       "260  github - langchain-ai/langchain-nextjs-templat...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [baskaryan, (, bagatur, ), ·, github, skip, to...   \n",
       "1    [langchain, academy, docs, python, langchain, ...   \n",
       "2    [sign, in, to, github, ·, github, skip, to, co...   \n",
       "3    [langgraph/contributing.md, at, main, ·, langc...   \n",
       "4    [why, langgraph, ?, skip, to, content, join, u...   \n",
       "..                                                 ...   \n",
       "256  [concepts, skip, to, content, join, us, at, in...   \n",
       "257  [the, mit, license, –, open, source, initiativ...   \n",
       "258  [nfcampos, (, nuno, campos, ), ·, github, skip...   \n",
       "259  [youtube, community, guidelines, and, policies...   \n",
       "260  [github, -, langchain-ai/langchain-nextjs-temp...   \n",
       "\n",
       "                                        cleaned_tokens  \\\n",
       "0    [baskaryan, bagatur, github, skip, to, content...   \n",
       "1    [langchain, academy, docs, python, langchain, ...   \n",
       "2    [sign, in, to, github, github, skip, to, conte...   \n",
       "3    [langgraphcontributingmd, at, main, langchaina...   \n",
       "4    [why, langgraph, skip, to, content, join, us, ...   \n",
       "..                                                 ...   \n",
       "256  [concepts, skip, to, content, join, us, at, in...   \n",
       "257  [the, mit, license, open, source, initiative, ...   \n",
       "258  [nfcampos, nuno, campos, github, skip, to, con...   \n",
       "259  [youtube, community, guidelines, and, policies...   \n",
       "260  [github, langchainailangchainnextjstemplate, l...   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    [baskaryan, bagatur, github, skip, to, content...  \n",
       "1    [langchain, academy, doc, python, langchain, l...  \n",
       "2    [sign, in, to, github, github, skip, to, conte...  \n",
       "3    [langgraphcontributingmd, at, main, langchaina...  \n",
       "4    [why, langgraph, skip, to, content, join, u, a...  \n",
       "..                                                 ...  \n",
       "256  [concept, skip, to, content, join, u, at, inte...  \n",
       "257  [the, mit, license, open, source, initiative, ...  \n",
       "258  [nfcampos, nuno, campos, github, skip, to, con...  \n",
       "259  [youtube, community, guideline, and, policy, h...  \n",
       "260  [github, langchainailangchainnextjstemplate, l...  \n",
       "\n",
       "[261 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride=40\n",
    "token_size=128\n",
    "data_list=[]\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split document into overlapping chunks\n",
    "def chunk_document(text, link):\n",
    "    words = text  # Tokenize the document into words\n",
    "    data_list = []  # Store chunks along with their link\n",
    "    i = 0\n",
    "\n",
    "    while i < len(words):\n",
    "            chunk = words[i:i + token_size]  # Extract chunk\n",
    "            i += stride  # Move by stride\n",
    "\n",
    "            # If the last chunk is shorter, pad it with '0'\n",
    "            while len(chunk) < token_size:\n",
    "                chunk.append('0')\n",
    "\n",
    "            data_list.append((' '.join(chunk), link)) \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for index, row in data_frame.iterrows():\n",
    "    processed_data.extend(chunk_document(row['lemmatized'], row['URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11077"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert processed data into a DataFrame\n",
    "df_chunks = pd.DataFrame(processed_data, columns=['tokens', 'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskaryan bagatur github skip to content navig...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manage code change discussion collaborate outs...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use case by industry healthcare financial serv...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fund open source developer the readme project ...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jump to search code repository user issue pull...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>different langchainjs module together you can ...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>out the doc here http jslangchaincomdocs deplo...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>comment reach out to u on twitter langchainai ...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>repository release no release published packag...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11076</th>\n",
       "      <td>can t perform that action at this time 0 0 0 0...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11077 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      baskaryan bagatur github skip to content navig...   \n",
       "1      manage code change discussion collaborate outs...   \n",
       "2      use case by industry healthcare financial serv...   \n",
       "3      fund open source developer the readme project ...   \n",
       "4      jump to search code repository user issue pull...   \n",
       "...                                                  ...   \n",
       "11072  different langchainjs module together you can ...   \n",
       "11073  out the doc here http jslangchaincomdocs deplo...   \n",
       "11074  comment reach out to u on twitter langchainai ...   \n",
       "11075  repository release no release published packag...   \n",
       "11076  can t perform that action at this time 0 0 0 0...   \n",
       "\n",
       "                                                    link  \n",
       "0                           https://github.com/baskaryan  \n",
       "1                           https://github.com/baskaryan  \n",
       "2                           https://github.com/baskaryan  \n",
       "3                           https://github.com/baskaryan  \n",
       "4                           https://github.com/baskaryan  \n",
       "...                                                  ...  \n",
       "11072  https://github.com/langchain-ai/langchain-next...  \n",
       "11073  https://github.com/langchain-ai/langchain-next...  \n",
       "11074  https://github.com/langchain-ai/langchain-next...  \n",
       "11075  https://github.com/langchain-ai/langchain-next...  \n",
       "11076  https://github.com/langchain-ai/langchain-next...  \n",
       "\n",
       "[11077 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting The Textual Data To Embeddings And Storing It In Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHASHANK_\\agenticAI\\env2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskaryan bagatur github skip to content navig...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manage code change discussion collaborate outs...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use case by industry healthcare financial serv...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fund open source developer the readme project ...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jump to search code repository user issue pull...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>different langchainjs module together you can ...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>out the doc here http jslangchaincomdocs deplo...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>comment reach out to u on twitter langchainai ...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>repository release no release published packag...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11076</th>\n",
       "      <td>can t perform that action at this time 0 0 0 0...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11077 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      baskaryan bagatur github skip to content navig...   \n",
       "1      manage code change discussion collaborate outs...   \n",
       "2      use case by industry healthcare financial serv...   \n",
       "3      fund open source developer the readme project ...   \n",
       "4      jump to search code repository user issue pull...   \n",
       "...                                                  ...   \n",
       "11072  different langchainjs module together you can ...   \n",
       "11073  out the doc here http jslangchaincomdocs deplo...   \n",
       "11074  comment reach out to u on twitter langchainai ...   \n",
       "11075  repository release no release published packag...   \n",
       "11076  can t perform that action at this time 0 0 0 0...   \n",
       "\n",
       "                                                    link  \n",
       "0                           https://github.com/baskaryan  \n",
       "1                           https://github.com/baskaryan  \n",
       "2                           https://github.com/baskaryan  \n",
       "3                           https://github.com/baskaryan  \n",
       "4                           https://github.com/baskaryan  \n",
       "...                                                  ...  \n",
       "11072  https://github.com/langchain-ai/langchain-next...  \n",
       "11073  https://github.com/langchain-ai/langchain-next...  \n",
       "11074  https://github.com/langchain-ai/langchain-next...  \n",
       "11075  https://github.com/langchain-ai/langchain-next...  \n",
       "11076  https://github.com/langchain-ai/langchain-next...  \n",
       "\n",
       "[11077 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Convert documents to embeddings\n",
    "document_embeddings = model.encode(df_chunks['tokens'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = document_embeddings.shape[1]\n",
    "dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Normalize embeddings before adding them to FAISS (cosine similarity)\n",
    "faiss.normalize_L2(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index\n",
    "index = faiss.IndexFlatIP(dimension)  # IP = Inner Product (used for cosine similarity)\n",
    "index.add(np.array(document_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Cohere client with your API key\n",
    "co = cohere.Client(\"zBcppvYKxb70AMbo7HVKBwcBrNIVVLuEZoTgHrbh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running In Playground "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskaryan bagatur github skip to content navig...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manage code change discussion collaborate outs...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use case by industry healthcare financial serv...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fund open source developer the readme project ...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jump to search code repository user issue pull...</td>\n",
       "      <td>https://github.com/baskaryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>different langchainjs module together you can ...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>out the doc here http jslangchaincomdocs deplo...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>comment reach out to u on twitter langchainai ...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>repository release no release published packag...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11076</th>\n",
       "      <td>can t perform that action at this time 0 0 0 0...</td>\n",
       "      <td>https://github.com/langchain-ai/langchain-next...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11077 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      baskaryan bagatur github skip to content navig...   \n",
       "1      manage code change discussion collaborate outs...   \n",
       "2      use case by industry healthcare financial serv...   \n",
       "3      fund open source developer the readme project ...   \n",
       "4      jump to search code repository user issue pull...   \n",
       "...                                                  ...   \n",
       "11072  different langchainjs module together you can ...   \n",
       "11073  out the doc here http jslangchaincomdocs deplo...   \n",
       "11074  comment reach out to u on twitter langchainai ...   \n",
       "11075  repository release no release published packag...   \n",
       "11076  can t perform that action at this time 0 0 0 0...   \n",
       "\n",
       "                                                    link  \n",
       "0                           https://github.com/baskaryan  \n",
       "1                           https://github.com/baskaryan  \n",
       "2                           https://github.com/baskaryan  \n",
       "3                           https://github.com/baskaryan  \n",
       "4                           https://github.com/baskaryan  \n",
       "...                                                  ...  \n",
       "11072  https://github.com/langchain-ai/langchain-next...  \n",
       "11073  https://github.com/langchain-ai/langchain-next...  \n",
       "11074  https://github.com/langchain-ai/langchain-next...  \n",
       "11075  https://github.com/langchain-ai/langchain-next...  \n",
       "11076  https://github.com/langchain-ai/langchain-next...  \n",
       "\n",
       "[11077 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function(query):\n",
    "    query_embedding = model.encode([query])\n",
    "    faiss.normalize_L2(query_embedding)  # Normalize query for cosine similarity\n",
    "\n",
    "    distances, indices = index.search(np.array(query_embedding),3)\n",
    "\n",
    "    results = []\n",
    "    for i in range(3):\n",
    "        doc_index = indices[0][i]\n",
    "        results.append({\n",
    "            'document': df_chunks.iloc[doc_index]['tokens'],\n",
    "            'similarity_score': float(distances[0][i]),\n",
    "            'links': df_chunks.iloc[doc_index]['link']  # Now it's cosine similarity\n",
    "        })\n",
    "    new=''\n",
    "    for j in results:\n",
    "        new=new+j['document']\n",
    "\n",
    "    urls=''\n",
    "    for k in results:\n",
    "        urls=urls+k['links']+','+' '\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    prompt  = f\"\"\"\n",
    "You are an AI assistant with deep knowledge of various topics. \n",
    "Use the following context to answer the user's question accurately in a summary form  covering all answer. \n",
    "If the context does not provide enough information, say \"I don't know\".\n",
    "If the context is not able to have information regarding query say\"I DONT KNOW\" \n",
    "\n",
    "    Context:\n",
    "   {new}\n",
    "\n",
    "   Question:\n",
    "   {query}\n",
    "\n",
    "   Answer (Be concise and informative):\n",
    "    \"\"\"\n",
    "\n",
    "    # Call Cohere’s API to generate text\n",
    "    response = co.generate(\n",
    "        model=\"command-xlarge-nightly\",  # Choose a Cohere model\n",
    "        prompt=prompt, \n",
    "        max_tokens=1000,  # Limit response length\n",
    "        temperature=0.5,  # Lower temp = more factual, higher = more creative\n",
    "        stop_sequences=[\"\\n\"]\n",
    "    )\n",
    "    answer=[]\n",
    "    answer.append(response.generations[0].text.strip())\n",
    "    answer.append(f' ,links:({urls})')\n",
    "    return ' '.join(answer)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain and Langgraph are both tools within the Langchain ecosystem, but they serve different purposes. Langchain provides a standard interface to interact with models and components, making it useful for straightforward retrieval and chain-of-thought processes. On the other hand, Langgraph is an orchestration framework designed for more complex, company-specific tasks, offering a low-level and controllable environment without the restrictions of a single black-box cognitive architecture. Langgraph is particularly beneficial for building and deploying agents with long-term memory capabilities, ensuring efficient performance without adding overhead to your code.  ,links:(https://academy.langchain.com/courses/intro-to-langgraph https://langchain-ai.github.io/langgraph/tutorials/introduction/ https://academy.langchain.com/courses/intro-to-langgraph )'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_function('what is the difference between langraph and langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# 🌈 AI Chatbot\")  # Styled heading\n",
    "    gr.Markdown(\"💡 **Ask me anything!** I'm here to assist you.\")\n",
    "    \n",
    "    with gr.Row():  # Arrange elements in a row\n",
    "        input_box = gr.Textbox(placeholder=\"Type your message...\", label=\"Your Query\")\n",
    "        submit_btn = gr.Button(\"🚀 Ask\")\n",
    "\n",
    "    output_box = gr.Textbox(label=\"Bot's Response\", lines=20)\n",
    "\n",
    "    submit_btn.click(final_function, inputs=input_box, outputs=output_box)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
